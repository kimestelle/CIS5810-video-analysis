{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1076928-e303-4976-8e8b-1d118f0bde64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/bin/python\n",
      "Requirement already satisfied: pip in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (25.2)\n",
      "Requirement already satisfied: faster-whisper in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (1.2.0)\n",
      "Requirement already satisfied: openai in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (2.1.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (4.56.2)\n",
      "Requirement already satisfied: pillow in /opt/homebrew/lib/python3.13/site-packages (11.1.0)\n",
      "Requirement already satisfied: opencv-python in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: torch in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (2.8.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.23.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from faster-whisper) (4.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from faster-whisper) (0.35.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from faster-whisper) (0.22.1)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from faster-whisper) (1.23.0)\n",
      "Requirement already satisfied: av>=11 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from faster-whisper) (15.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.8.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.13/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (2.2.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\n",
      "Requirement already satisfied: coloredlogs in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.9.23)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.2)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (6.32.1)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.14.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from huggingface-hub>=0.13->faster-whisper) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from huggingface-hub>=0.13->faster-whisper) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from huggingface-hub>=0.13->faster-whisper) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from huggingface-hub>=0.13->faster-whisper) (1.1.10)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from openai) (2.11.9)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/opt/certifi/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torchvision-0.23.0-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "Downloading torchaudio-2.8.0-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torchaudio]2\u001b[0m [torchaudio]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torchaudio-2.8.0 torchvision-0.23.0\n",
      "Requirement already satisfied: ipywidgets in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install faster-whisper openai requests tqdm transformers pillow opencv-python torch torchvision torchaudio\n",
    "!{sys.executable} -m pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcf5f1ce-29c6-4a26-953f-a303109090d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "#openai for LLM functionality\n",
    "OPENAI_API_KEY = \"\"\n",
    "#assembly for video to text script\n",
    "ASSEMBLYAI_API_KEY = \"\"\n",
    "#google cloud for video analysis (also try Amazon Rekognition, Microsoft Azure Video Indexer, Clarifai)\n",
    "GCP_API_KEY = \"\"\n",
    "\n",
    "VIDEO_PATH = \"good_place_clip.mp4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e3dbbb-8e66-40cd-bb7c-43c86b73246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_to_text(video_path: str) -> dict:\n",
    "    headers = {\"authorization\": ASSEMBLYAI_API_KEY}\n",
    "    # uplkoad video\n",
    "    upload_url = \"https://api.assemblyai.com/v2/upload\"\n",
    "    def read_file(filename, chunk_size=5242880):\n",
    "        with open(filename, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(chunk_size)\n",
    "                if not data:\n",
    "                    break\n",
    "                yield data\n",
    "    up_resp = requests.post(upload_url, headers=headers, data=read_file(video_path))\n",
    "    audio_url = up_resp.json()['upload_url']\n",
    "\n",
    "    # transcribe\n",
    "    transcribe_url = \"https://api.assemblyai.com/v2/transcript\"\n",
    "    transcribe_req = {\"audio_url\": audio_url, \n",
    "                      \"speaker_labels\": True,\n",
    "                      \"iab_categories\": True, # topics\n",
    "                      \"entity_detection\": True,\n",
    "                      \"sentiment_analysis\": True,\n",
    "                      \"auto_chapters\": True}\n",
    "    t_resp = requests.post(transcribe_url, headers=headers, json=transcribe_req)\n",
    "    transcript_id = t_resp.json()['id']\n",
    "\n",
    "    # keep polling until complete\n",
    "    poll_url = f\"{transcribe_url}/{transcript_id}\"\n",
    "    while True:\n",
    "        poll_resp = requests.get(poll_url, headers=headers)\n",
    "        status = poll_resp.json()['status']\n",
    "        if status == 'completed':\n",
    "            return poll_resp.json()\n",
    "        elif status == 'error':\n",
    "            raise RuntimeError(poll_resp.json()['error'])\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9ec1a9d-975d-4375-be4d-ab643a3d2d30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/estellekim/Projects/5810_video_analysis\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "transcript_result = transcribe_to_text(VIDEO_PATH)\n",
    "transcript_text = transcript_result.get(\"text\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0996602-dd7f-4814-ba5b-e62f27a1727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "Was I ever good at being sad? Partly because my mom straight up told me not to be. But this is sad, man. You got a John Locke quote or a piece of Kantian wisdom you can throw at me? Those guys were more focused on rules and regulations. For spiritual stuff, you gotta turn to the east. I'll take anything you got. Hit me. Picture a wave in the ocean. You can see it. Measure it. Its height, the way the sunlight refracts when it passes through. And it's there and you can see it. You know what it is? It's a wave. And then it crashes on the shore. And it's gone. But the water is still there. The wave was just a different way for the water to be for a little while. That's one conception of death for a Buddhist. The wave returns to the ocean where it came from and where it's supposed to be. Not bad. Buddhists, not bad. None of this is bad. I need you to do me one last favor. Say goodbye to me now and leave before I wake up. Sam. You can sit on that bench as long as you'd like. And whenever you're ready, you just walk through. I'm ready. It.\n",
      "Entities:\n",
      "person_name: John Locke\n",
      "religion: tian\n",
      "religion: Buddhist\n",
      "religion: Buddhists\n",
      "person_name: Sam\n",
      "Categories:\n",
      "('Religion&Spirituality>Atheism', 0.001717198)\n",
      "('BooksAndLiterature>YoungAdultLiterature', 0.0009056844)\n",
      "('Sports>MartialArts', 0.00091915915)\n",
      "('Hobbies&Interests>ParanormalPhenomena', 0.003020115)\n",
      "('Religion&Spirituality>Hinduism', 0.0012440904)\n",
      "('Sports>ExtremeSports>CanoeingAndKayaking', 0.0011586394)\n",
      "(\"HealthyLiving>Men'sHealth\", 0.0011139238)\n",
      "('Religion&Spirituality', 0.009714233)\n",
      "('MusicAndAudio>Religious(MusicAndAudio)', 0.0018644918)\n",
      "('MedicalHealth>DiseasesAndConditions>MentalHealth', 0.0028957515)\n",
      "('Religion&Spirituality>Buddhism', 0.682685)\n",
      "('Religion&Spirituality>Agnosticism', 0.0033551892)\n",
      "('Travel>TravelType>BeachTravel', 0.0018630624)\n",
      "('Religion&Spirituality>Spirituality', 0.03076621)\n",
      "('HealthyLiving>Wellness>AlternativeMedicine', 0.0009982726)\n",
      "('Sports>ExtremeSports>SurfingAndBodyboarding', 0.0069111013)\n",
      "('FamilyAndRelationships>Bereavement', 1.0)\n",
      "('EventsAndAttractions>PersonalCelebrations&LifeEvents>Funeral', 0.030787315)\n",
      "('MedicalHealth>DiseasesAndConditions>SleepDisorders', 0.0013869343)\n",
      "('FamilyAndRelationships>Parenting>ParentingChildrenAged4-11', 0.001348195)\n"
     ]
    }
   ],
   "source": [
    "print(\"Text:\")\n",
    "print(transcript_result.get(\"text\", \"\")) \n",
    "\n",
    "print(\"Entities:\")\n",
    "for e in transcript_result.get(\"entities\", []):\n",
    "    print(f\"{e['entity_type']}: {e['text']}\")\n",
    "\n",
    "print(\"Categories:\")\n",
    "if \"iab_categories_result\" in transcript_result:\n",
    "    summary = transcript_result[\"iab_categories_result\"].get(\"summary\", {})\n",
    "    for name in summary.items():\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47522d65-9175-4b7a-8a6d-90b1528379e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-03 00:00:56.940] [ctranslate2] [thread 5310330] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model = WhisperModel(\"small\")\n",
    "segments, info = model.transcribe(VIDEO_PATH)\n",
    "transcript = [{\"start\": s.start, \"end\": s.end, \"text\": s.text} for s in segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3d27ee-f3a0-4021-a800-592a04d5d9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What was ever good at being sad? Probably because my mom straight up told me not to be. But this is sad, man. You got a John Locke quote, or a piece of county and wisdom you can throw at me? Those guys were more focused on rules and regulations. For spiritual stuff, you got to turn to the east. I'll take anything you got. Hit me. Picture a wave in the ocean. You can see it, measure it, its height, the way the sunlight refracts when it passes through, and it's there, and you can see it. You know what it is. It's a wave. And then it crashes on the shore, and it's gone, but the water is still there. The wave was just a different wave for the water to be for a little while. That's one conception of death for a Buddhist. The wave returns to the ocean. Where it came from. And where it's supposed to be. Not bad, Buddhists. Not bad. None of this is bad. I need you to do me one last favor. Say goodbye to me now, and leave before I wake up. You can sit on that bench as long as you'd like, and whenever you're ready, you just walk through. I'm ready.\n",
      "[{'start': 0.0, 'end': 4.0, 'text': ' What was ever good at being sad?'}, {'start': 4.0, 'end': 8.0, 'text': ' Probably because my mom straight up told me not to be.'}, {'start': 8.0, 'end': 12.0, 'text': ' But this is sad, man.'}, {'start': 12.0, 'end': 15.0, 'text': ' You got a John Locke quote,'}, {'start': 15.0, 'end': 18.0, 'text': ' or a piece of county and wisdom you can throw at me?'}, {'start': 18.0, 'end': 22.0, 'text': ' Those guys were more focused on rules and regulations.'}, {'start': 22.0, 'end': 27.0, 'text': ' For spiritual stuff, you got to turn to the east.'}, {'start': 27.0, 'end': 33.0, 'text': \" I'll take anything you got. Hit me.\"}, {'start': 33.0, 'end': 39.0, 'text': ' Picture a wave in the ocean.'}, {'start': 39.0, 'end': 42.0, 'text': ' You can see it, measure it, its height,'}, {'start': 42.0, 'end': 46.0, 'text': ' the way the sunlight refracts when it passes through,'}, {'start': 46.0, 'end': 49.0, 'text': \" and it's there, and you can see it.\"}, {'start': 49.0, 'end': 52.0, 'text': \" You know what it is. It's a wave.\"}, {'start': 52.0, 'end': 55.0, 'text': ' And then it crashes on the shore,'}, {'start': 55.0, 'end': 58.0, 'text': \" and it's gone,\"}, {'start': 58.0, 'end': 64.0, 'text': ' but the water is still there.'}, {'start': 64.0, 'end': 68.0, 'text': ' The wave was just a different wave'}, {'start': 68.0, 'end': 75.0, 'text': ' for the water to be for a little while.'}, {'start': 75.0, 'end': 79.0, 'text': \" That's one conception of death for a Buddhist.\"}, {'start': 79.0, 'end': 84.0, 'text': ' The wave returns to the ocean.'}, {'start': 85.0, 'end': 89.0, 'text': ' Where it came from.'}, {'start': 89.0, 'end': 93.0, 'text': \" And where it's supposed to be.\"}, {'start': 93.0, 'end': 94.0, 'text': ' Not bad, Buddhists.'}, {'start': 94.0, 'end': 98.0, 'text': ' Not bad.'}, {'start': 98.0, 'end': 108.0, 'text': ' None of this is bad.'}, {'start': 108.0, 'end': 113.0, 'text': ' I need you to do me one last favor.'}, {'start': 113.0, 'end': 118.0, 'text': ' Say goodbye to me now, and leave before I wake up.'}, {'start': 143.0, 'end': 169.0, 'text': \" You can sit on that bench as long as you'd like,\"}, {'start': 169.0, 'end': 172.0, 'text': \" and whenever you're ready,\"}, {'start': 172.0, 'end': 176.0, 'text': ' you just walk through.'}, {'start': 176.0, 'end': 178.0, 'text': \" I'm ready.\"}]\n"
     ]
    }
   ],
   "source": [
    "transcript_text_only = ''.join([s[\"text\"] for s in transcript])\n",
    "print(transcript_text_only)\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f3f1c83-c0b9-4921-b027-2edfc5048a55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# take frames every 1 second of the video to put into image analysis\n",
    "\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frames = []\n",
    "frame_id = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if frame_id % int(fps) == 0:  # 1 fps\n",
    "        frames.append(frame)\n",
    "    frame_id += 1\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a022b4d-5ec2-4ecc-964b-16ceb32735ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec9b1c18-0e18-4164-a11e-c95b7ef14967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8003d493c04b379891bafeb554f781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393ba2840a7c4de58dd98c4cf48ffb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be150a145504cdaafadb88b37ef755c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# analyze and capture each frame\n",
    "\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# https://huggingface.co/Salesforce/blip-image-captioning-base\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "captions = []\n",
    "for f in frames:\n",
    "    image = Image.fromarray(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs)\n",
    "    captions.append(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e88c7eda-d6e1-4de3-a95f-665cfe9c8d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a black background with a white and red flower', 'a person sitting on a balcony watching the sunset', 'a person sitting on a couch watching a sunset', 'a couple sitting on a balcony watching the sunset', 'a couple sitting on a balcony watching the sunset', 'a couple sitting on a couch watching the sunset', 'a woman sitting on a couch', 'a woman sitting on a couch with a man', 'a woman sitting on a couch next to a man', 'a woman sitting on a couch next to a man', 'a woman sitting on a couch', 'a woman sitting on a couch', 'a woman sitting on a couch next to a man', 'a woman sitting on a couch', 'watch this gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi', 'a woman sitting on a couch next to a man', 'watch this video of a $ $ $ from the movie', 'watch this gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi', 'watch this gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi', 'a woman sitting on a couch next to a man', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a woman sitting on a couch next to a man', 'a woman sitting on a couch next to a man', 'a woman sitting on a couch next to a man', 'a woman sitting on a couch next to a man', 'a woman sitting on a couch next to a man', 'a woman sitting on a couch next to a man', 'a woman sitting on a couch next to a man', 'watch this gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi', 'a man and a woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and a woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and a woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and a woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a bed', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a bed', 'a man and woman sitting on a couch', 'a woman sitting on a couch next to a man', 'a man and a woman sitting on a couch', 'a woman sitting on a couch next to a man', 'a man and woman sitting on a couch', 'a woman sitting on a couch next to a man', 'a woman sitting on a couch next to a man', 'a man and woman sitting on a couch', 'a man and a woman sitting on a couch', 'a woman in a white shirt and glasses', 'a woman in a white shirt and glasses sitting next to a man', 'a woman in a white shirt and glasses sitting next to a man', 'a woman sitting next to a man in a suit', 'a woman sitting next to a man in a chair', 'a woman in a white shirt and glasses', 'a woman in a white shirt and glasses', 'watch this gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi', 'a woman in a white shirt and glasses sitting next to a man', 'a woman in a white shirt and glasses sitting next to a man', 'a woman in a white shirt and glasses sitting next to a man', 'a woman in a white shirt and glasses sitting next to a man', 'a woman in a white shirt and glasses', 'watch this gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi', 'a woman in a white shirt and glasses sitting next to a man', 'watch this gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi', 'a woman in a white shirt and glasses sitting next to a man', 'a woman in a white shirt and glasses sitting next to a man', 'a woman in a white shirt and glasses', 'watch this gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi', 'watch this gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi', 'watch this gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi gi', 'a woman in a white shirt and glasses', 'a man and woman are looking at each other people', 'a man and woman sitting next to each other people', 'a man and woman sitting next to each other people', 'a man and woman sitting next to each other people', 'a man and woman sitting next to each other people', 'a man and woman looking at each other people', 'a man and woman looking at each other people', 'a man and woman looking at each other people', 'a man and woman looking at each other people', 'a man and woman looking at a cell', 'a man and woman looking at each other people', 'a man and woman looking at a cell', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a man and woman sitting on a couch', 'a woman in a white shirt and glasses looking at a man', 'a woman in a white shirt and glasses is hugging a man', 'a woman in a white shirt and glasses is looking at a man in a black suit', 'a woman in a white shirt and glasses is looking at a man in a black suit', 'a man and woman are sitting together', 'a man and woman are sitting together', 'a man and woman sitting on a couch', 'a man and woman are sitting together', 'a man and woman are standing together', 'a man and woman are sitting together', 'a man and woman sitting together', 'a man and woman in a room with a light on', 'a man and woman in a room with a light on', 'a man and woman in a room with a light on', 'a man and woman in a room with a light on', 'a man and woman are hugging in a room', 'a man and woman are hugging in a room', 'a man and woman in a room', 'a person sitting on a bench watching the sunset', 'a person sitting on a bench looking at the sunset', 'a person sitting on a rock looking at the sunset', 'a person sitting on a ledge watching the sunset', 'a person sitting on a ledge watching the sunset', 'a person sitting on a ledge looking at the sunset', 'a person sitting on a couch looking out at the sunset', 'a woman sleeping in bed with her eyes closed', 'a woman laying in bed with her head on the pillow', 'a woman laying in bed with her eyes closed', 'a woman laying in bed with her eyes closed', 'a woman laying in bed with her eyes closed', 'a woman laying in bed with her head on the pillow', 'a woman laying in bed with a book', 'a woman laying in bed with a pillow', 'a woman laying in bed with a book', 'a woman laying in bed with a book', 'a woman laying in bed with a book', 'a young girl is reading a book in bed', 'a woman laying in bed', 'a woman laying in bed', 'a woman laying in bed with a book', 'a woman laying in bed reading a book', 'a woman laying in bed', 'a woman laying in bed with a book', 'a woman laying in bed with a cat', 'a woman laying in bed', 'a little girl is laying in bed reading a book', 'a little girl is reading a book on a bed', 'a little girl is reading a book on a bed', 'a woman laying in bed', 'a woman and a child are laying in bed', 'a little girl is reading a book on a bed', 'a woman laying in bed', 'a woman laying in bed', 'a little girl is reading a book on a bed', 'a woman laying on a bed with a book', 'a woman laying in bed with a dog', 'a woman sitting on a bed with a pillow', 'a woman sitting on a bed with a pillow', 'a woman sitting on a bed with a pillow', 'a large group of redwood trees in the forest', 'a woman standing in the middle of a forest', 'a woman standing in the middle of a forest', 'a woman in a purple dress is walking through the woods', 'a couple standing in the woods', 'a man and woman standing in the woods', 'a woman is walking through a tunnel in the woods', 'a couple walking through a forest with a tunnel', 'a couple walking through a forest with a tunnel', 'a couple walking through a forest with a tunnel', 'a couple walking through a forest with a tunnel', 'a couple walking through a forest with a tunnel', 'a man and woman standing in the woods', 'a man and woman standing in the woods', 'a woman in a purple dress standing next to a man in a forest', 'a man and woman standing in the woods', 'a man and woman standing in the woods', 'a man and woman standing in the woods', 'a man and woman standing in the woods', 'a man and woman standing in the woods', 'a man and woman standing in the woods', 'a man and woman standing in the woods', 'a woman is standing next to a man in the woods', 'a woman hugging a man in the woods', 'a woman is hugging a man in the woods', 'a man in a white shirt and sunglasses standing in front of a tree', 'a man and woman kissing in the woods', 'a man and woman standing in front of a tree', 'a man and woman standing in front of a tree', 'a man and woman standing in front of a tree', 'a couple walking through a forest', 'a couple walking through a forest with trees', 'a couple walking through a forest with a tunnel', 'a man and woman walking through a tunnel of trees', 'a man and woman walking through a tunnel of trees', 'a woman in a purple dress standing in the woods', 'a woman in a purple dress standing in the woods']\n"
     ]
    }
   ],
   "source": [
    "print(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9b747-2ebf-4264-b283-f9e4ace3fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate frame descrptions with text transcript and previous assembly results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d2a22-e78f-47b6-9374-fc0dbb6f21eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output as organized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35a008-66d6-4ed7-8d63-46722fe6d99f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
